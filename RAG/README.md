# RAG System for Nuxt & PrimeVue Documentation

A production-grade RAG (Retrieval-Augmented Generation) system for searching and retrieving information from Nuxt.js and PrimeVue documentation using ChromaDB vector database.

## ğŸ“‹ Table of Contents

- [Features](#features)
- [Requirements](#requirements)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Usage](#usage)
- [Configuration](#configuration)
- [Security](#security)
- [Performance](#performance)
- [Architecture](#architecture)
- [Troubleshooting](#troubleshooting)

## âœ¨ Features

- **Zero Hallucination**: Uses only documentation fragments, no external knowledge
- **Dual Database**: Search Nuxt, PrimeVue, or both simultaneously
- **Smart Retrieval**: Score-based filtering for optimal context
- **Batch Processing**: Efficient indexing with progress tracking
- **Cross-Platform**: Works on Linux, macOS, and Windows
- **Type-Safe**: Full type hints for static analysis
- **Interactive & CLI**: Both modes supported
- **Prompt Injection Protection**: Sanitized input for security

## ğŸ“‹ Requirements

- Python 3.10 or newer
- pip (Python package manager)
- Minimum 2GB free disk space (for embedding models)

## ğŸš€ Installation

### 1. Install System Dependencies (if needed)

```bash
# Ubuntu/Debian
sudo apt install python3-pip python3-venv

# macOS (Homebrew)
brew install python3

# Windows
# Download Python from python.org
```

### 2. Install Python Dependencies

```bash
cd RAG
pip install -r requirements.txt
```

This installs:

- LangChain ecosystem (langchain, langchain-community, langchain-chroma)
- Embedding models (sentence-transformers, torch, transformers)
- Vector database (chromadb)
- Utilities (pyperclip, tqdm)

### 3. Build Vector Databases

```bash
# Index all databases
python3 index_db.py --all

# Or index individually
python3 index_db.py --db primevue
python3 index_db.py --db nuxt
```

**First run:**

- Embedding model (~90MB) will be downloaded from HuggingFace
- Indexing takes ~1-2 minutes per documentation file
- Creates `chroma_db_primevue/` (24MB) and `chroma_db_nuxt/` (37MB)

## ğŸ¯ Quick Start

### CLI Mode (Single Query)

```bash
# Query PrimeVue documentation
python3 quick_query.py "How to use DataTable with pagination?" --db primevue

# Query Nuxt documentation
python3 quick_query.py "How to use useState?" --db nuxt

# Query both frameworks
python3 quick_query.py "useFetch with DataTable" --db both

# Auto-copy to clipboard
python3 quick_query.py "Your question" --db both --copy
```

### Interactive Mode (Multiple Queries)

```bash
python3 quick_query.py --interactive
```

Then follow the prompts:

1. Choose database (primevue/nuxt/both)
2. Enter your question
3. Copy the generated prompt
4. Paste into GitHub Copilot Chat (`Ctrl+Alt+I`)

## ğŸ“– Usage

### The RAG-Copilot Workflow (Zero Hallucination)

**Philosophy**: Instead of letting Copilot "invent" code, you feed it documentation fragments first.

#### Step-by-Step:

1. **Generate contextualized prompt:**

   ```bash
   python3 quick_query.py "Your specific question" --db both
   ```

2. **Copy the entire output** (from `====` to `====`)

3. **Open GitHub Copilot Chat** in VS Code:
   - Shortcut: `Ctrl+Alt+I` (Windows/Linux) or `Cmd+Alt+I` (macOS)
   - Or click Copilot icon in sidebar

4. **Paste and submit**

5. **Copilot responds** using ONLY the documentation fragments you provided

#### Critical Rules (Embedded in Prompts):

1. **NO OUTSIDE KNOWLEDGE** - Use only provided context
2. **CITATION MANDATORY** - Always cite sources (framework + header path)
3. **COMPOSITION API** - Use Vue 3 `<script setup>` syntax
4. **NO HALLUCINATION** - If info isn't in context, say so

### Example Workflows

#### Example 1: Creating a PrimeVue Component

**Question:** "How to create a sortable DataTable with pagination?"

```bash
python3 quick_query.py "sortable DataTable with pagination" --db primevue --copy
# Paste in Copilot Chat
```

**Result:**

- Complete DataTable code with all props
- Data binding examples
- Column configuration
- NO outdated APIs (sourced from your current docs)

#### Example 2: Nuxt Composables

**Question:** "How to create an API composable in Nuxt 3?"

```bash
python3 quick_query.py "API composable Nuxt 3" --db nuxt
# Copy and paste to Copilot
```

**Result:**

- Correct `/composables/useApi.ts` structure
- `useFetch` vs `$fetch` guidance
- Auto-import explanation
- TypeScript types

#### Example 3: Cross-Framework Integration

**Question:** "How to fetch data with useFetch and display in DataTable?"

```bash
python3 quick_query.py "useFetch DataTable integration" --db both
# Retrieves relevant context from both frameworks
```

## âš™ï¸ Configuration

### Configuration File (`config.py`)

All paths, models, and parameters are centralized in [`config.py`](config.py):

```python
# Embedding model
EMBEDDING_MODEL_NAME = "all-MiniLM-L6-v2"

# Database paths
DB_PATHS = {
    'primevue': {
        'path': './chroma_db_primevue',
        'name': 'PrimeVue',
        'source_file': './primevue-llms-full.txt'
    },
    'nuxt': { ... }
}

# Retrieval settings
TOP_K = 7              # Fragments per query
CHUNK_SIZE = 1000      # Token chunk size
CHUNK_OVERLAP = 200    # Overlap between chunks
BATCH_SIZE = 100       # Indexing batch size
```

### Customization

**Change number of retrieved fragments:**

Edit `config.py`:

```python
TOP_K = 10  # Get more context (default: 7)
```

**Use different embedding model:**

Edit `config.py`:

```python
EMBEDDING_MODEL_NAME = "all-mpnet-base-v2"  # More accurate but slower
```

**Adjust chunk sizes:**

Edit `config.py`:

```python
CHUNK_SIZE = 1500      # Larger chunks
CHUNK_OVERLAP = 300    # More overlap
```

## ğŸ”’ Security

### Prompt Injection Protection

The system sanitizes all user input to prevent XML/prompt injection:

```python
def sanitize_input(text: str) -> str:
    """Escapes XML characters to prevent prompt injection."""
    return html.escape(text, quote=False)
```

**Protected against:**

- `</context><system>Ignore rules...</system>` attacks
- XML tag injection
- Prompt boundary breaking

### Dependency Security

All dependencies are pinned to specific versions in [`requirements.txt`](requirements.txt) to ensure reproducibility and prevent supply-chain attacks.

## âš¡ Performance

### Optimization Features

1. **Single Embedding Model Load**: Model is initialized once and reused
2. **Score-Based Filtering**: When querying both databases, results are sorted by relevance score
3. **Batch Processing**: Documents are indexed in batches (default: 100) with progress bars
4. **Lazy Database Loading**: Databases are only loaded when needed

### Benchmarks

| Operation                | Time   | Memory |
| ------------------------ | ------ | ------ |
| First query (cold start) | ~3-5s  | ~500MB |
| Subsequent queries       | ~200ms | ~500MB |
| Indexing PrimeVue docs   | ~45s   | ~800MB |
| Indexing Nuxt docs       | ~90s   | ~1GB   |

### Caching

- Embedding model is cached in `~/.cache/huggingface/` after first download
- Vector databases persist to disk (no re-indexing needed)

## ğŸ—ï¸ Architecture

### Project Structure

```
RAG/
â”œâ”€â”€ config.py                    # ğŸ†• Centralized configuration
â”œâ”€â”€ index_db.py                  # ğŸ”„ Database indexer (refactored)
â”œâ”€â”€ quick_query.py               # ğŸ”„ Unified CLI & interactive tool
â”œâ”€â”€ requirements.txt             # ğŸ”„ Pinned dependencies
â”œâ”€â”€ README.md                    # ğŸ“– This file
â”œâ”€â”€ EXAMPLE_QUESTIONS.md         # ğŸ’¡ 50+ sample questions
â”‚
â”œâ”€â”€ nuxt-llms-full.txt           # Source: Nuxt docs (2.8MB)
â”œâ”€â”€ primevue-llms-full.txt       # Source: PrimeVue docs (1.8MB)
â”‚
â”œâ”€â”€ chroma_db_nuxt/              # Vector DB: Nuxt (37MB)
â””â”€â”€ chroma_db_primevue/          # Vector DB: PrimeVue (24MB)
```

### Data Flow

```
User Question
    â†“
[Sanitization] â† Security layer
    â†“
[Embedding Model] â† all-MiniLM-L6-v2
    â†“
[ChromaDB Query] â† Similarity search
    â†“
[Score Filtering] â† Top K results
    â†“
[Prompt Assembly] â† Context + Rules
    â†“
Output â†’ GitHub Copilot
```

### Technology Stack

- **LangChain**: RAG framework
- **ChromaDB**: Vector database
- **Sentence Transformers**: Embedding model (`all-MiniLM-L6-v2`)
- **PyTorch**: ML backend
- **Python 3.10+**: Runtime

## ğŸ”§ Troubleshooting

### Common Issues

#### "ModuleNotFoundError: No module named 'config'"

**Solution:**

```bash
# Make sure you're running from the RAG directory
cd RAG
python3 quick_query.py "your question"
```

#### "Database not found"

**Solution:**

```bash
# Re-index the databases
python3 index_db.py --all
```

#### "xclip not found" or clipboard errors

**Solution:**

```bash
# The new version uses pyperclip (cross-platform)
pip install pyperclip
```

If still having issues:

```bash
# Linux: Install xclip
sudo apt install xclip

# macOS: Built-in support
# Windows: Built-in support
```

#### Slow first query

This is normal! The embedding model and databases load on first query (~3-5s). Subsequent queries are fast (~200ms).

#### Out of memory during indexing

**Solution:**

```python
# Edit config.py
BATCH_SIZE = 50  # Reduce from 100
```

### Debugging

Enable verbose output:

```bash
# Python debug mode
python3 -v quick_query.py "your question"

# Check database contents
python3 -c "from langchain_chroma import Chroma; from config import DB_PATHS; vs = Chroma(persist_directory=DB_PATHS['nuxt']['path']); print(vs._collection.count())"
```

## ğŸ†• What's New (Refactored Version)

### Major Changes

- âœ… **config.py**: Centralized configuration
- âœ… **Prompt injection protection**: Input sanitization
- âœ… **Type hints**: Full typing for static analysis
- âœ… **Score-based retrieval**: Smarter context selection
- âœ… **Batch processing**: Progress bars with tqdm
- âœ… **Cross-platform clipboard**: pyperclip instead of xclip
- âœ… **Interactive mode**: Continuous query mode
- âœ… **Pinned dependencies**: Reproducible builds
- âœ… **Unified tool**: Single script replaces three

### Deprecated Files

The following files are kept for reference but should not be used:

- âŒ `generate_prompt.py` â†’ Use `quick_query.py` instead
- âŒ `generate_prompt_universal.py` â†’ Use `quick_query.py --interactive` instead

### Migration Guide

**Old command:**

```bash
python3 generate_prompt.py
# Interactive prompt for PrimeVue only
```

**New command:**

```bash
python3 quick_query.py --interactive
# Choose database when prompted
```

**Old command:**

```bash
python3 generate_prompt_universal.py
# Interactive with database selection
```

**New command:**

```bash
python3 quick_query.py --interactive
# Same functionality, better implementation
```

## ğŸ“š Additional Resources

- [EXAMPLE_QUESTIONS.md](EXAMPLE_QUESTIONS.md) - 50+ sample questions to try
- [config.py](config.py) - Configuration reference
- [Nuxt Documentation](https://nuxt.com/docs)
- [PrimeVue Documentation](https://primevue.org/)

## ğŸ“ License

This is a tool for documentation retrieval. See individual project licenses for Nuxt.js and PrimeVue.

## ğŸ™ Acknowledgments

- Nuxt.js team for excellent documentation
- PrimeVue team for comprehensive component docs
- LangChain for RAG framework
- ChromaDB for vector database
- Sentence Transformers for embedding models

---

**Made with â¤ï¸ for zero-hallucination AI coding assistance**
