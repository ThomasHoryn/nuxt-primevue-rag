# GitHub Copilot Instructions - RAG System dla Nuxt & PrimeVue

## Kontekst projektu

To jest system RAG (Retrieval-Augmented Generation) do wyszukiwania informacji w dokumentacji Nuxt.js i PrimeVue przy uÅ¼yciu bazy wektorowej ChromaDB.

## Stack technologiczny

### Backend (Python)

- **LangChain** - framework do budowy aplikacji LLM
- **ChromaDB** - baza wektorowa do przechowywania embeddingÃ³w
- **Sentence Transformers** - model `all-MiniLM-L6-v2` do generowania embeddingÃ³w
- **FastAPI** (planowane) - API REST

### Frontend (planowany)

- **Nuxt 3** - framework Vue.js
- **PrimeVue** - biblioteka komponentÃ³w UI
- **TypeScript**

## Struktura projektu

```
nuxt-primevue-rag/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ copilot-instructions.md
â”œâ”€â”€ RAG/
â”‚   â”œâ”€â”€ index_db.py              # Indeksowanie dokumentÃ³w
â”‚   â”œâ”€â”€ generate_prompt.py       # Generator promptÃ³w (PrimeVue)
â”‚   â”œâ”€â”€ generate_prompt_universal.py  # Generator promptÃ³w (Universal)
â”‚   â”œâ”€â”€ QUICKSTART.md            # Quick start guide
â”‚   â”œâ”€â”€ USAGE.md                 # PeÅ‚na dokumentacja uÅ¼ycia
â”‚   â”œâ”€â”€ EXAMPLE_QUESTIONS.md     # PrzykÅ‚adowe pytania
â”‚   â”œâ”€â”€ nuxt-llms-full.txt       # Dokumentacja Nuxt
â”‚   â”œâ”€â”€ primevue-llms-full.txt   # Dokumentacja PrimeVue
â”‚   â”œâ”€â”€ chroma_db_nuxt/          # Baza wektorowa Nuxt
â”‚   â”œâ”€â”€ chroma_db_primevue/      # Baza wektorowa PrimeVue
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
```

## ğŸ¯ RAG-Copilot Workflow (ZERO HALUCYNACJI)

### Filozofia

Zamiast pozwalaÄ‡ Copilotowi wymyÅ›laÄ‡ kod, **karmisz go fragmentami dokumentacji** przed kaÅ¼dym pytaniem.

### Workflow:

1. Uruchom `python3 generate_prompt_universal.py`
2. Zadaj pytanie (np. "Jak zrobiÄ‡ DataTable w PrimeVue?")
3. Skopiuj wygenerowany prompt (zawiera fragmenty dokumentacji)
4. Wklej do GitHub Copilot Chat w VS Code
5. Copilot odpowiada TYLKO na podstawie dostarczonych fragmentÃ³w

### Critical Rules dla promptÃ³w:

```
1. NO OUTSIDE KNOWLEDGE - uÅ¼ywaj tylko kontekstu
2. CITATION MANDATORY - cytuj ÅºrÃ³dÅ‚a (Headers)
3. COMPOSITION API - uÅ¼ywaj <script setup>
4. NO HALLUCINATION - zero wymyÅ›lania API
```

### Gdy uÅ¼ywasz tego systemu jako Copilot:

- âœ… Analizuj **tylko** fragmenty w `<context>`
- âœ… Cytuj ÅºrÃ³dÅ‚a: "Å¹rÃ³dÅ‚o: Header 1 > Header 2"
- âœ… UÅ¼ywaj wzorcÃ³w kodu dokÅ‚adnie jak w dokumentacji
- âŒ NIE wymyÅ›laj API ktÃ³re nie sÄ… w kontekÅ›cie
- âŒ NIE uÅ¼ywaj wiedzy spoza dostarczonych fragmentÃ³w

## Konwencje kodowania

### Python

- **Style**: PEP 8
- **Naming**: snake_case dla funkcji i zmiennych
- **Docstrings**: Google style
- **Type hints**: uÅ¼ywaj wszÄ™dzie gdzie moÅ¼liwe
- **Imports**: grupuj w kolejnoÅ›ci: stdlib, third-party, local

### PrzykÅ‚ad kodu Python:

```python
from typing import List, Dict
from langchain_chroma import Chroma
from langchain_community.embeddings import SentenceTransformerEmbeddings

def retrieve_documents(query: str, k: int = 5) -> List[Dict]:
    """
    Wyszukuje najbardziej podobne dokumenty do zapytania.

    Args:
        query: Pytanie uÅ¼ytkownika
        k: Liczba dokumentÃ³w do zwrÃ³cenia

    Returns:
        Lista dokumentÃ³w z metadanymi
    """
    pass
```

### TypeScript/Vue (gdy bÄ™dzie frontend)

- **Style**: Standard Vue 3 + Composition API
- **Naming**: camelCase dla zmiennych, PascalCase dla komponentÃ³w
- **Components**: Single File Components (.vue)
- **Composables**: prefix `use` (np. `useRAGQuery`)

## Kluczowe parametry projektu

### Chunking dokumentÃ³w

```python
chunk_size = 1000        # Rozmiar fragmentu tekstu
chunk_overlap = 200      # NakÅ‚adanie miÄ™dzy fragmentami
```

### Wyszukiwanie

```python
k = 5                    # Liczba zwracanych dokumentÃ³w
model = "all-MiniLM-L6-v2"  # Model embeddingowy
```

## WskazÃ³wki dla Copilot

1. **ObsÅ‚uga bÅ‚Ä™dÃ³w**: Zawsze dodawaj try-except dla operacji I/O i poÅ‚Ä…czeÅ„ z bazÄ…
2. **Logowanie**: UÅ¼ywaj emoji w printach dla lepszej czytelnoÅ›ci (ğŸ“–, ğŸ§ , âœ…, âŒ)
3. **Komentarze**: UÅ¼ywaj polskich komentarzy dla spÃ³jnoÅ›ci z resztÄ… kodu
4. **Embeddingi**: PamiÄ™taj o cache'owaniu modelu embeddingowego
5. **Chunking**: Zawsze zachowuj kontekst nagÅ‚Ã³wkÃ³w Markdown
6. **Metadane**: Dodawaj ÅºrÃ³dÅ‚o dokumentu (nuxt/primevue) do kaÅ¼dego fragmentu

## Status funkcjonalnoÅ›ci

- [x] Indeksowanie dokumentacji (index_db.py)
- [x] Generator promptÃ³w dla pojedynczej bazy (generate_prompt.py)
- [x] Universal generator dla wielu baz (generate_prompt_universal.py)
- [x] Python CLI wrapper (quick_query.py)
- [x] VSCode Extension (rag-copilot-helper)
- [x] VSCode Tasks + Keybindings
- [x] Dokumentacja uÅ¼ycia (QUICKSTART.md, USAGE.md, EXAMPLE_QUESTIONS.md, AUTOMATION.md)
- [x] Konfiguracja VSCode dla Copilot
- [ ] FastAPI backend z endpointem /api/query
- [ ] Frontend w Nuxt 3 z interfejsem czatu
- [ ] System cache'owania czÄ™sto zadawanych pytaÅ„
- [ ] Deployment (Docker)

## ğŸš€ NarzÄ™dzia automatyzacji

### VSCode Extension (Recommended)

**Najlepszy DX:** One-click RAG queries bezpoÅ›rednio w VS Code!

```bash
cd .vscode-extension
npm install
code --install-extension rag-copilot-helper-*.vsix
```

**UÅ¼ycie:** `Ctrl+Shift+R` â†’ pytanie â†’ DONE!

### Python CLI

```bash
python3 RAG/quick_query.py "Your question" --db both --copy
```

### VSCode Tasks

- `Ctrl+Shift+R Q` - Quick Query
- `Ctrl+Shift+R P` - Query PrimeVue
- `Ctrl+Shift+R N` - Query Nuxt
- `Ctrl+Shift+R B` - Query Both

PeÅ‚na dokumentacja: [AUTOMATION.md](../AUTOMATION.md)

## PrzykÅ‚adowe zapytania do systemu RAG

- "Jak uÅ¼ywaÄ‡ composables w Nuxt 3?"
- "Jak skonfigurowaÄ‡ DataTable w PrimeVue?"
- "Jaka jest rÃ³Å¼nica miÄ™dzy pages i components w Nuxt?"
- "Jak stylowaÄ‡ komponenty PrimeVue?"

## Dane ÅºrÃ³dÅ‚owe

- `nuxt-llms-full.txt` - 2.8 MB - peÅ‚na dokumentacja Nuxt
- `primevue-llms-full.txt` - 1.8 MB - peÅ‚na dokumentacja PrimeVue

Dokumenty sÄ… w formacie Markdown z nagÅ‚Ã³wkami strukturyzujÄ…cymi treÅ›Ä‡.

## Uwagi dotyczÄ…ce wydajnoÅ›ci

- Model embeddingowy (~90MB) jest cache'owany po pierwszym uÅ¼yciu
- Pierwsza indeksacja moÅ¼e trwaÄ‡ 1-2 minuty
- Zapytania do bazy sÄ… szybkie (~100-200ms)
- Baza wektorowa zajmuje Å‚Ä…cznie ~61MB
